{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "\n",
        "<div class=\"markdown-google-sans\">\n",
        "<h2>Chatgpt-PDF</h2>\n",
        "</div>\n",
        "\n",
        "The developed chatbot is designed to efficiently address frequently asked questions (FAQs) by leveraging cutting-edge technologies like OpenAI and Langchain. It's been specifically trained on a PDF document containing the FAQ content. When presented with a user's query, the chatbot intelligently processes the input, extracts the relevant information from the PDF, and provides a precise and accurate response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Install Dependencies**\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "OrN9jexXL_OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Train Dataset**\n",
        "</div>\n",
        "\n",
        "1.   Data Collection\n",
        "\n",
        "> The project began with collecting a PDF file containing frequently asked questions and their corresponding answers. This PDF file served as the knowledge base for the chatbot.\n",
        "\n",
        "2.   PDF Processing\n",
        "\n",
        "> The PDF file was processed to extract text and convert it into a structured format that the chatbot could work with. This involved using libraries like PyPDF2 or other PDF processing tools.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2fGIT0HrMIRj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Training the Model**\n",
        "</div>\n",
        "\n",
        "\n",
        "1.   Open the **app.py** file in your code editor.\n",
        "2.   Locate the section where the OpenAI API key needs to be added.\n",
        "3.   Insert your OpenAI API key in the designated place. If you haven't obtained an API key yet, make sure to sign up on the OpenAI platform and acquire your API key.\n",
        "4.   Save the **app.py** file.\n",
        "5.   You are now ready to initiate the training process.\n",
        "\n",
        "**Note:** Ensure that you keep your API key confidential and do not share it publicly.\n",
        "\n",
        "\n",
        "\n",
        "1.   Open your terminal or command prompt.\n",
        "2.   Execute the following command:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python3 app.py"
      ],
      "metadata": {
        "id": "s78n2okOPtZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "\n",
        "\n",
        "3.   To train the model, execute app.py. This script will utilize your training dataset Upon completion, the trained model will be ready for deployment.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4HZx7Gndbrh"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'OPENAI_API_KEY'\n",
        "\n",
        "docsearch = None\n",
        "chain = None\n",
        "rqa = None\n",
        "directory = './data'\n",
        "\n",
        "def load_docs(directory):\n",
        "  loader = DirectoryLoader(directory)\n",
        "  print(loader)\n",
        "  documents = loader.load()\n",
        "  return documents\n",
        "\n",
        "def loadPDF():\n",
        "    print(\"LOAD PDF\")\n",
        "\n",
        "    raw_text = ''\n",
        "    documents = load_docs(directory)\n",
        "    for document in documents:\n",
        "        if document.page_content:\n",
        "            raw_text +=  document.page_content\n",
        "    print(\"raw_text : \", raw_text)\n",
        "\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator = \"\\n\",\n",
        "        chunk_size = 1000,\n",
        "        chunk_overlap  = 200, #striding over the text\n",
        "        length_function = len,\n",
        "    )\n",
        "    texts = text_splitter.split_text(raw_text)\n",
        "\n",
        "\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    global docsearch\n",
        "    docsearch = FAISS.from_texts(texts, embeddings)\n",
        "    docsearch.embedding_function\n",
        "    global chain\n",
        "    chain = load_qa_chain(OpenAI(), chain_type=\"stuff\") # we are going to stuff all the docs in at once\n",
        "\n",
        "    chain.llm_chain.prompt.template\n",
        "\n",
        "    retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":4})\n",
        "\n",
        "    global rqa\n",
        "    rqa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "    print(\"PDF LOADED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_kCnsPUqS6o"
      },
      "source": [
        "\n",
        "4.   Once the training process is complete, The API will be accessible on port 3001, allowing users to interact with the chatbot.\n",
        "\n",
        "    Link : http://localhost:3001/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example\n",
        "\n",
        "1.   Which Languages supported?\n",
        "2.   Does it supported in Desktop Offfline mode?\n",
        "3.   How solutions offer currently?\n",
        "\n",
        "# Implementation Demo link\n",
        "  \n",
        "1.   link: http://122.169.118.18:3001/\n",
        "\n"
      ],
      "metadata": {
        "id": "g8bsrJILRqSb"
      }
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
